---
title: "DDSCaseStudy2"
author: "Benjamin Wilke, Manny Rosales, Amy Paschal"
date: "April 2, 2018"
output:
  html_document:
    keep_md: true
---

###### Source files can be found at https://github.com/bpwilke/DDSCaseStudy2

```{r setup, include=FALSE}
# Load necessary packages and ensure they are active
load.lib = c("kableExtra","ggplot2","Amelia","pastecs","ROCR","reshape2","devtools","glmnet")

install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
  install.packages(lib,dependencies=TRUE)
} 

sapply(load.lib,require,character=TRUE)

knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(kableExtra) # to make uber sexy tables for output
#library(ggbiplot) # implementation of biplot using ggplot2 for plotting PCs
library(pastecs) # for easy descriptive statistics
library(ROCR) # for ROC plots and AUC calculations
library(glmnet)
# turn off scientfic notation for the entire script
# set precision of decimal place to 2
options(scipen = 999, digits=2)
```
<span style="color:blue;font-size:32px;font-style: italic; font-weight: bold;">DDSAnalytics</span>
<span style="font-style: italic; font-weight: bold;">Specializing in talent management solutions for Fortune 1000 companies</span>

## Introduction
Cabbot Laboratories has engaged DDSAnalytics to provide insight on employee attrition, including:

* Overview of the current attrition situation
* Determination of factors that lead to attrition
* Prediction of future employee turnover

```{r, echo=TRUE}
# load raw data
employeeDatRaw <- read.csv('CaseStudy2data.csv', header=TRUE)
```

## Data Cleanup and Conversion

#### Checking for missing data values

```{r, echo=TRUE}
# check for missing data values
numNAs <- sum(apply(employeeDatRaw,2,is.na))
```

Fortunately, this data is not missing any values as demonstrated by the code ran above and output below.

##### Number of missing data values = `r numNAs`

#### Columns with no variation have no impact on attrition

We found several columns that don't have any variation and will actually cause future model building to fail. The code below is used to identify and remove those colomns. We also convert the response Attrition to numeric for future use.

```{r, echo=TRUE}

# look for and drop columns with no variation
drop_columns <- which(apply(employeeDatRaw, 2, function(x) (length(unique(x)) == 1)))
cols <- names(drop_columns)
employeeDatRaw <- employeeDatRaw[,-drop_columns]

# find columns of class factor
factor_columns <- names(which(sapply(names(employeeDatRaw),function(x) class(employeeDatRaw[[x]])=="factor")))

# convert factors to numeric
employeeDatRaw$Attrition <- as.numeric(employeeDatRaw$Attrition)-1
```

##### Dropped columns: `r cols`

## Attrition Rates (Competitor Analysis)

### By Industry

Cabbot Laboratories is a leader in the healthcare industry providing top tier pharmaceuticals, medical devices, diagnostics, and nutrition products.
As such, we look to the healthcare and manufacturing industries for competitive analysis.

```{r, echo=TRUE}

# determine overall attrition rate
attritionRate <- (sum(employeeDatRaw$Attrition) / nrow(employeeDatRaw)) * 100

ind <- c("Overall","Healthcare","Manufacturing")
vol <- c(13.5, 15.9, 11.1)
total <- c(18.5, 20.5, 17.0)
industryRates <- data.frame(ind,vol,total)
names(industryRates) <- c("Industry", "Voluntary(%)", "Total(%)")

# display industry attrition
knitr::kable(industryRates, caption = "Attrition Rates. Per Compdata Surveys & Consulting's Turnover Report 2017", row.names = FALSE, "html") %>%
  kable_styling(bootstrap_options = c("striped","hover", "condensed", "responsive"))
```
##### reference: http://blog.compdatasurveys.com/employee-turnover-trends-in-2017

### By Job Role

#### Healthcare industry attrition in Sales is 14.1%

##### reference: https://radford.aon.com/insights/articles/2016/Turnover-Rates-for-Sales-Employees-Reach-a-Five-Year-High

## Voluntary Attrition Rates (Cabbot Laboratories)

##### Overall attrition rate: `r attritionRate`%

<style>
caption {
      color: black;
      font-weight: bold;
      font-size: 1.0em;
      text-align:center;
    } 
</style>

### Demographic Analysis
```{r, echo=TRUE, results="asis"}

#############################################################
# Determine and display attrition rates by attribute.
#############################################################

# AgeRange doesn't exist so it needs to be created.
# AgeRange is used for statistical binning of ages.

# generate age range bin
ageBin <- function(x) {
  if (x < 25) return ("< 25")
  if (x < 35) return ("25-35")
  if (x < 45) return ("35-45")
  if (x < 55) return ("45-55")
  return("55 and >")
}

attritionRaw <- employeeDatRaw
attritionRaw$AgeRange <- sapply(attritionRaw$Age, ageBin)

# attributes of interest
# to change the set of attributes for which attrition rates are calculated,
# simply change the next line
attritionAttrs <- c("Department", "JobRole", "JobLevel", "Gender", "AgeRange")

###########################################################
# helper functions for generating and displaying data
###########################################################

# generateAttritionDF generates a dataframe for attrition by attr, where attr is an
# attribute (aka column) of the attrition dataframe
generateAttritionDF <- function(attr,df) {
  # construct the "by" list for the aggregate function
  attrList <- list(df[[attr]])
  names(attrList)[1] <- attr

  # aggreate by attribute, counting the number of observations where attrition is true
  attritionByAttr <- aggregate(df$Attrition,by=attrList,FUN=sum)
  
  # determine number of observations for each attribute value
  sizeByAttr <- count(df,attr)
  
  # merge into a new dataframe and calculate the attrition rate for each attribute value
  attritionRateByAttr <- merge(attritionByAttr, sizeByAttr, by=attr)
  names(attritionRateByAttr) <- c(attr, "Attrition", "PopulationSize")
  
  # calculate attrition rate and format as percentage
  attritionRateByAttr$AttritionRate <- (attritionRateByAttr$Attrition / attritionRateByAttr$PopulationSize) * 100
  
  # sort by attrition rate, descending
  attritionRateByAttr <- attritionRateByAttr[order(attritionRateByAttr$AttritionRate, decreasing = TRUE),]
  return(attritionRateByAttr)
}

# displayAttritionAttr displays the given data frame in a table with an appropriate title
displayAttritionAttr <- function(attr, df) {
    title <- paste("Attrition Rates by ", attr)
    df$AttritionRate <- sapply(df$AttritionRate, function(x) sprintf("%.0f%%", x)) # format rate as a percentage
    print(knitr::kable(df, caption = title, row.names = FALSE, "html", align="r") %>% kable_styling(bootstrap_options = c("striped","hover", "condensed", "responsive"), full_width = F))
    return
}

#########################################################
# end helper functions
#########################################################



# generate a table and display it for each attribute (column) of interest
for (attr in attritionAttrs) {
  displayAttritionAttr(attr, generateAttritionDF(attr, attritionRaw))
 
}
```

### Summary
#### Overall voluntary attrition is slightly above industry average at `r attritionRate`% vs. 16%. 

## Areas of High Attrition
* Attrition in the Sales Department is above the healthcare industry average for sales (21% vs 14.1%), most notably among Sales Representatives who are at 40%
* The Human Resources Department is also above the healthcare industry average (19% vs. 16%)
* Within Research & Development, Laboratory Technician is significantly above average at 24%
* Job Level 1 is significantly above average at 26%
* Attrition by gender shows only a 2% difference
* Among those 25 and Under and 25-35 attrition is above industry average at 39% and 20% respectively. However, attrition is typically above the average in the younger age ranges.
* Attrition among the 55 and Over age range is at industry average. However attrition typically goes down as age increases and this age range is above that of the two preceeding ranges

# Exploratory Data Analysis

From the data provided we can clearly see that there is a subset of variabes that are continuous and another that are categorical. In order to better understand the distribution and skew of the continuous numerical columns a set of faceted histograms was generated. Other than Age which appears normaly distributed, it is clear that most columns are right skewed. Each factor for the categorical columns is summarized in a review. One of the more interesting distributions include YearsSinceLastPromotion, the large right skew could indicate a significant factor associated with attrition.

We also notice from the data that EmployeeCount and StandardHours are the same value for all employees and are not meaningful variables. Similarly, EmployeeNumber does not produce any meaingful information given that each employee has a unique EmployeeNumber.

When incorporating Attrition into the histograms it appears that those with more YearsAtCompany are less likely to leave the company. A similar trend is obsered with MonthlyIncome, the larger the MonthlyIncome the less Attrition is observed. Finally those with a higher JobLevel also appear to have less attrition than those with lower JobLevel values.

``` {r MannyEDA, echo=TRUE,fig.height = 16, fig.width = 10, fig.align="center"}
# descriptive statistics, load into new data frame for processing
descriptiveTable <- pastecs::stat.desc(employeeDatRaw)

# remove non-numeric features
charCols <- c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "Over18", "OverTime")
continuousTable.stats <- descriptiveTable[,!(colnames(descriptiveTable) %in% charCols)]
categoricalTable <- employeeDatRaw[,(colnames(descriptiveTable) %in% charCols)]
continuousTable <- employeeDatRaw[,!(colnames(employeeDatRaw) %in% charCols)]

# remove rows for certain descriptive statistics leaving: N, Mean, Median, Std Dev, Var, Min, Max
remove <- c("CI.mean.0.95", "nbr.val", "nbr.null", "nbr.na", "range", "sum", "SE.mean", "CI.mean", "coef.var")
continuousTable.stats <- continuousTable.stats[-which(rownames(continuousTable.stats) %in% remove),]

# round all numeric values to 2 decimal points
continuousTable.stats <- round(continuousTable.stats, 2)
continuousTable.transposed <- t(continuousTable.stats) # object becomes matrix

# display descriptive statistics
knitr::kable(continuousTable.transposed,caption = "Descriptive Statistics for Numeric Features in the Raw Employee Data", row.names = TRUE, "html") %>%
  kable_styling(bootstrap_options = c("striped","hover", "condensed", "responsive"), full_width = F)

summary(categoricalTable)

continuousTable$Attrition <- employeeDatRaw$Attrition
continuousTable$EmployeeCount <- NULL
continuousTable$EmployeeNumber <- NULL
continuousTable$StandardHours <- NULL

facetPlot <- melt(continuousTable, id.vars = "Attrition")

p <- ggplot(data = facetPlot, aes(x = value, fill=Attrition)) + 
    geom_histogram(bins = 10, colour = "black") + 
    facet_wrap(~variable, scales = 'free', ncol = 4) + 
    labs(title="Faceted Histograms for Continuous Variables", title_x="", title_y="") +
    scale_fill_manual(values = c("darkgrey","red")) 
    
#p

# the above ggplot doesn't seem to render correctly in RMarkdown, but it does in R Studio if you're curious. Therefore, we are displaying the result as a static image loaded from GitHub.
```

![](https://github.com/bpwilke/DDSCaseStudy2/blob/MannyWorking2/DDS_CaseStudy2_files/ImageBackup.png?raw=true)

# Exploring Attrition with Binomial Logistic Regression

Binomial logistic regression is a special form of mutiple regression that is used to model a dichotomous outcome. In our case, this outcome is whether an employee left the company or is still a current employee.

The executive leadership has identified predicting employee turnover as a primary application of data science for talent management. We will use binomial logistic regression to understand how certain explanatory variables may influence the likelihood of empoyee attrition. We will also identify a prediction model using explanatory variables in the data provided. This model can be used to identify high risk individuals to prioritize corrective action to improve employee attrition.

The first model will use all available continuous and categorical variables - that is, fitting a full model. Some variables must be left out as they do not have any variability and will cause the model fitting to error. These varables are: EmployeeCount, StandardHours, and Over18. For more information on these variables please review the Exploratory Data Analysis section.

The model will be fitted on 80% of the data selected at random from the raw data. The remaining 20% will be used to assess the prediction capability.

```{r, echo=TRUE, fig.width=6}

# copy data set, we can remove features with the dropcolumns as needed to play with the model
# I'm dropping variables with no variation per this 
# https://stackoverflow.com/questions/18171246/error-in-contrasts-when-defining-a-linear-model-in-r
# Solution: There is not enough variation in dependent variable with only one value. So, you need to drop that variable, irrespective of whether that is numeric or character or factor variable.

employee_logistic <- employeeDatRaw
dropcolumns <- c("EmployeeCount", "StandardHours", "Over18")
employee_logistic <- employee_logistic[,!(colnames(employee_logistic) %in% dropcolumns)]

# convert Attrition to 1 and 0 from character based factor
# convert factor levels to numeric
employee_logistic$Attrition <- as.numeric(as.factor(employee_logistic$Attrition))
# change the 2's (No) to 0's
employee_logistic$Attrition[employee_logistic$Attrition == 2] <- 0
# convert back to factor
employee_logistic$Attrition <- as.factor(employee_logistic$Attrition)

# split the raw data into testing and training data
set.seed(50) # set seed so that same sample can be reproduced in future

# now selecting 80% of data as sample from total 'n' rows of the data  
sample <- sample.int(n=nrow(employee_logistic), size=floor(.80*nrow(employee_logistic)), replace=FALSE)

# subset the data using the sample integer vector created above
train <- employee_logistic[sample, ]
test  <- employee_logistic[-sample, ]

# fitting the binomial logistic regression model, Attrition is dependent, fitting using all features
model <- glm(train$Attrition ~., family=binomial(link='logit'),data=train)

summary(model)
```

We will now test the predictive capablity of this full model.

```{r, echo=TRUE}
# predict based on the test data, type='response' output probabilities in the form of P(y=1|X)
fittedresults <- predict(model, newdata=test, type='response')

# if P(y=1|X) > 0.5 then y = 1 otherwise y=0
fittedresults <- ifelse(fittedresults > 0.5, 1, 0)

# calculate the mean of the fitted results that don't equal the observed result - IGNORE NAs
misClasificError <- mean(fittedresults != test$Attrition, na.rm=TRUE) # this adds up all the instances of misclassification then divides by total (via mean)

# print the output as 100% - error
print(paste('Accuracy',1-misClasificError))
```

The model already exhibits very high predictive capability (86.4%), but we will now refit the model using only variables with signficance from the full model. This is done to simplify the model for interpretation and to reduce potential multicolinearity issues.

The model will be fit with the following features:

BusinessTravel<br>
DistanceFromHome<br>
EnvironmentSatisfaction<br>
Gender<br>
JobInvolvement<br>
JobRole<br>
JobSatisfaction<br>
MaritalStatus<br>
NumCompaniesWorked<br>
OverTime<br>
RelationshipSatisfaction<br>
TotalWorkingYears<br>
TrainingTimesLastYear<br>
WorkLifeBalance<br>
YearsAtCompany<br>
YearsInCurrentRole<br>
YearsSinceLastPromotion<br>
YearsWithCurrManager

```{r, echo=TRUE}
employee_logistic <- employeeDatRaw
dropcolumns <- c("EmployeeCount", "StandardHours", "Over18") # revmoving these again, because they can't be used in the model
employee_logistic <- employee_logistic[,!(colnames(employee_logistic) %in% dropcolumns)]

# keep only features as noted above (and Attrition for predictions)
keepcolumns <- c("BusinessTravel", "DistanceFromHome", "EnvironmentSatisfaction",
"Gender", "JobInvolvement", "JobRole", "JobSatisfaction", "MaritalStatus",
"NumCompaniesWorked", "OverTime", "RelationshipSatisfaction",
"TotalWorkingYears", "TrainingTimesLastYear", "WorkLifeBalance",
"YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion",
"YearsWithCurrManager", "Attrition")
employee_logistic <- employee_logistic[,(colnames(employee_logistic) %in% keepcolumns)]

# convert Attrition to 1 and 0 from character based factor
# convert factor levels to numeric
employee_logistic$Attrition <- as.numeric(as.factor(employee_logistic$Attrition))
# change the 2's (No) to 0's
employee_logistic$Attrition[employee_logistic$Attrition == 2] <- 0
# convert back to factor
employee_logistic$Attrition <- as.factor(employee_logistic$Attrition)

# split the raw data into testing and training data
set.seed(50) # set seed so that same sample can be reproduced in future

# now selecting 80% of data as sample from total 'n' rows of the data  
sample <- sample.int(n=nrow(employee_logistic), size=floor(.80*nrow(employee_logistic)), replace=FALSE)

# subset the data using the sample integer vector created above
train <- employee_logistic[sample, ]
test  <- employee_logistic[-sample, ]

# fitting the binomial logistic regression model, Attrition is dependent, fitting using all features
model <- glm(train$Attrition ~., family=binomial(link='logit'),data=train)

summary(model)
```

We will now test the predictive capablity of this reduced model.

```{r, echo=TRUE}
# predict based on the test data, type='response' output probabilities in the form of P(y=1|X)
fittedresults <- predict(model, newdata=test, type='response')

# if P(y=1|X) > 0.5 then y = 1 otherwise y=0
fittedresults <- ifelse(fittedresults > 0.5, 1, 0)

# calculate the mean of the fitted results that don't equal the observed result - IGNORE NAs
misClasificError <- mean(fittedresults != test$Attrition, na.rm=TRUE) # this adds up all the instances of misclassification then divides by total (via mean)

# print the output as 100% - error
print(paste('Accuracy',1-misClasificError))
```

The predictive capability of this reduced model improved slightly to 88.77% and has now been simplifed quite a bit in terms of the number of features.

# Using GLMNET and Cross-Validation for Feature Selection of Logistic Regression

Our earlier approach was to intuitively select features from the data that represented statistical and practical significance to the question of interest. In this section we will employ an automated feature selection tool that leverages LASSO (Least Absolute Shrinkage and Selection Operator) and cross-validation to select important features in the model. 

```{r, echo=TRUE}
employee_logistic <- employeeDatRaw
dropcolumns <- c("EmployeeCount", "StandardHours", "Over18") # removing these again, because they can't be used in the model
employee_logistic <- employee_logistic[,!(colnames(employee_logistic) %in% dropcolumns)]

# convert Attrition to 1 and 0 from character based factor
# convert factor levels to numeric
employee_logistic$Attrition <- as.numeric(as.factor(employee_logistic$Attrition))
# change the 2's (No) to 0's
employee_logistic$Attrition[employee_logistic$Attrition == 2] <- 0
# convert back to factor
employee_logistic$Attrition <- as.factor(employee_logistic$Attrition)

# split the raw data into testing and training data
set.seed(50) # set seed so that same sample can be reproduced in future

# now selecting 80% of data as sample from total 'n' rows of the data  
sample <- sample.int(n=nrow(employee_logistic), size=floor(.80*nrow(employee_logistic)), replace=FALSE)

# subset the data using the sample integer vector created above
train <- employee_logistic[sample, ]
test  <- employee_logistic[-sample, ]

# # # START GLMNET for Logistic Regression Feature Selection # # # # # # # # # # # # # # # # # # # # # # # # # # # # 

# isolate the binary response "Attrition" from the training data
GLMTrain.y <- train$Attrition
GLMTrain.y <- as.factor(as.character(GLMTrain.y))

# create train data set while removing "Attrition" from the training data
GLMTrain.x <- train[,!(colnames(train) == "Attrition")]

#Categorical variables are usually first transformed into factors, then a dummy variable matrix of predictors is created and along with the continuous predictors, is passed to the model. Keep in mind, glmnet uses both ridge and lasso penalties, but can be set to either alone.

# isolate categorical/factors from the continuous features, create dummy variable matrix for all factors
GLMTrain.xfactors <- model.matrix(GLMTrain.y ~ GLMTrain.x$BusinessTravel + GLMTrain.x$Department + GLMTrain.x$EducationField + GLMTrain.x$Gender + GLMTrain.x$JobRole + GLMTrain.x$MaritalStatus + GLMTrain.x$OverTime)[, -1]

# remove categorical/factors from GLMTrain.x as they will be added back in the form of dummy variable matrix from above
dropcolumns <- c("BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime") 
GLMTrain.x <- GLMTrain.x[,!(colnames(GLMTrain.x) %in% dropcolumns)]

# combine GLMTrain.x continuous variables with GLMTrain.xfactors dummy variable matrix, then converting whole thing to a matrix for glmnet
GLMTrain.x <- as.matrix(data.frame(GLMTrain.x, GLMTrain.xfactors))

# use glmnet to fit a binomial logistic regression
glmnetfit <- cv.glmnet(GLMTrain.x, GLMTrain.y, family = "binomial", alpha=1)

plot(glmnetfit)
```

The above plot shows us that the optimal value of lambda in the LASSO model (the value that minimizes the mean square error) is approximately -5.75. We want to provide the smallest number of coeffecients, but also give good accuracy. For this, we will use the value of lambda that lies within one standard error of the optimal value of lamda to display those coeffecients that are significant.

```{r, echo=TRUE}
lambda_lse <- glmnetfit$lambda.1se
coef(glmnetfit, s=lambda_lse)
```

These significant coeffecients are:

Age<br>
DistanceFromHome<br>
EnvironmentSatisfaction<br>
JobInvolvement<br>
JobSatisfaction<br>
MonthlyIncome<br>
NumCompaniesWorked<br>
RelationshipSatisfaction<br>
StockOptionLevel<br>
TotalWorkingYears<br>
TrainingTimesLastYear<br>
WorkLifeBalance<br>
YearsInCurrentRole<br>
YearsSinceLastPromotion<br>
YearsWithCurrManager<br>
Department<br>
EducationField<br>
JobRole<br>
MaritalStatus<br>
OverTimeYes<br>

This is 20 total features, which is actually 2 more than our reduced model!

We will proceed to test the predictive capability of this model like we've done before using the 20% of testing data.

```{r, echo=TRUE}
# # # START Prediction from GLMNET fit model # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

# prepare the test data in a similar manner for GLMNET usage (create dummy variables, matrix, etc.)
# create test data set while removing "Attrition" from the test data
GLMTest.x <- test[,!(colnames(test) == "Attrition")]

# isolate the binary response "Attrition" from the test data
GLMTest.y <- test$Attrition
GLMTest.y <- as.factor(as.character(GLMTest.y))

# isolate categorical/factors from the continuous features, create dummy variable matrix for all factors
GLMTest.xfactors <- model.matrix(GLMTest.y ~ GLMTest.x$BusinessTravel + GLMTest.x$Department + GLMTest.x$EducationField + GLMTest.x$Gender + GLMTest.x$JobRole + GLMTest.x$MaritalStatus + GLMTest.x$OverTime)[, -1]

# remove categorical/factors from GLMTest.x as they will be added back in the form of dummy variable matrix from above
dropcolumns <- c("BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime") 
GLMTest.x <- GLMTest.x[,!(colnames(GLMTest.x) %in% dropcolumns)]

# combine GLMTest.x continuous variables with GLMTest.xfactors dummy variable matrix, then converting whole thing to a matrix for glmnet
GLMTest.x <- as.matrix(data.frame(GLMTest.x, GLMTest.xfactors))

# predict based on the test data, type='response' output probabilities in the form of P(y=1|X)
GLMfittedresults <- predict(glmnetfit, newx=GLMTest.x, type='response')

# if P(y=1|X) > 0.5 then y = 1 otherwise y=0
GLMfittedresults <- ifelse(GLMfittedresults > 0.5, 1, 0)

# calculate the mean of the fitted results that don't equal the observed result - IGNORE NAs
misClasificError <- mean(GLMfittedresults != GLMTest.y, na.rm=TRUE) # this adds up all the instances of misclassification then divides by total (via mean)

# print the output as 100% - error
print(paste('Accuracy',1-misClasificError))

```

This model exhibits less predictive capability on the hold out test set (86.39% accuracy). For this reason, we will use the reduced model as our final recommendation for predicting attrition. These features included:

BusinessTravel<br>
DistanceFromHome<br>
EnvironmentSatisfaction<br>
Gender<br>
JobInvolvement<br>
JobRole<br>
JobSatisfaction<br>
MaritalStatus<br>
NumCompaniesWorked<br>
OverTime<br>
RelationshipSatisfaction<br>
TotalWorkingYears<br>
TrainingTimesLastYear<br>
WorkLifeBalance<br>
YearsAtCompany<br>
YearsInCurrentRole<br>
YearsSinceLastPromotion<br>
YearsWithCurrManager


# ROC Curve for our Final (Reduced) Predictive Model

An ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system like our logistic regression model. The curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR)

```{r, echo=TRUE}
#Create ROC curves
pr <- prediction(fittedresults, test$Attrition)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

#Ref line indicating poor performance, 50/50
abline(a=0, b= 1)

# calculate area under curve (AUC)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]

# print AUC onto plot
text(x = .40, y = .6,paste("AUC = ", round(auc,3), sep = ""))




